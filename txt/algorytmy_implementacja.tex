\section{Implementacja algorytmów SocialPageRank i AdaptedPageRank}

Zarówno algorytm SocialPageRank i AdaptedPageRank wykorzystują w trakcie każdej iteracji sześć macierzy. Trzy z sześciu używanych macierzy zostały opisane poniżej.  Kolejne trzy to ich transpozycje.

Używane macierze:

\begin{itemize}
\item $M_{DU}$: macierz $N_D \times N_D$ asocjacyjna między dokumentami a użytkownikami, która w każdej komórce $M_{DU}(d_m, u_k)$ zawiera ilość tagów, którymi dany użytkownik $u_k$ opisał wybrany dokument $d_m$.
\item $M_{UT}$: macierz $N_U \times N_T$  asocjacyjna między użytkownikami a tagami, zawierająca w komórce ilość dokumentów opisanych wybranym tagiem przez danego użytkownika/
\item $M_{TD}$: macierz $N_T \times N_D$ asocjacyjna między tagami a dokumentami, zawierająca w komórach liczbę użytkowników, którzy dany dokument opisali wybranym tagiem.

\end{itemize}

Algorytmy te działały na danych składających sie z około 200,000 użytkowników, 300,000 dokumentów i 80,000 tagów. Macierze utworzone z tych danych są duże. Dodatkowo, w algorytmie Adapted PageRank używamy macierzy, która jest stworzona ze wszystkich 6-ciu opisanych powyżej:

\[
 G_f =
 \begin{pmatrix}
  0                     & M_{DU}       & M_{TD}^T \\
  M_{DU}^T  & 0                     & M_{UT}     \\
  M_{TD}       & M_{UT}^T   & 0 
 \end{pmatrix}
\]

Problemem jest nie tylko sama wielkość macierzy, które nie mogą zmieścić sie jednocześnie w pamięci, ale również ich zawartość. Wyliczanie danych przy każdej iteracji jest bardzo czasochłonne. Dlatego, żeby nie wyliczać zawartości macierzy przy każdej iteracji, potrzebujemy zapamiętać ich zawartość. Dodatkowo, wyliczanie, choćby jednorazowe, danych jest bardzo kosztowne.

Żeby rozwiązać te problemy, na początku wykonywany jest preprocessing w bazie danych, wyliczający wymagane dane. Następnie, dane te są zapisywane na dysku w łatwą do użycia później strukturę danych, która zawiera tylko określoną ilość wierszy macierzy.


Pliki te później są używane jako fragmenty macierzy. Na tych fragmentach wykonywane są wymagane obliczenia. Kolejne wyniki obliczeń są następnie łączone i przekazywane do kolejnej iteracji, albo zwracane jako wynik algorytmu.


